{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 1 con DataFrame sin nulos\n",
    "### Vamos a comenzar realizando un árbol de desición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_properties = pd.read_csv(\"datasets/properties_train_wn.csv\")\n",
    "df_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminamos columnas que no vamos a utilizar\n",
    "df_properties.drop(['Unnamed: 0','price'], axis=1, inplace=True)\n",
    "df_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df_properties.corr(method='spearman'), annot=True, fmt='.1g', cmap='coolwarm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determinamos las columnas que vamos a utilizar para ver su correlación con el precio\n",
    "columnas = ['sqfeet','beds','baths','cats_allowed','dogs_allowed','smoking_allowed','wheelchair_access','electric_vehicle_charge','comes_furnished']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos un objeto de la clase DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth = 3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos el archivo de test\n",
    "df_properties_test = pd.read_parquet(\"datasets/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo\n",
    "X = df_properties[columnas]  # Denotamos X con mayúscula ya que incluye más de un atributo\n",
    "y = df_properties.category_price # Etiqueta a predecir\n",
    "clf.fit(X.values,y.values) #entrenamos con train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "y_pred = clf.predict(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(\"La precisión del modelo es: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos el modelo con el archivo de test\n",
    "X_train = df_properties[columnas]\n",
    "y_train = df_properties['category_price']\n",
    "\n",
    "X_test = df_properties_test[columnas]\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "df_properties_test['category_price']= y_pred\n",
    "y_test = df_properties_test['category_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_properties_test['category_price'].to_csv('datasets/YamiGaliano.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 1.2 remplazando cualitativos en cuantitativos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a pasar variables cualitativas a cuantitativas: type, laundry_options y parking_options. Region y state los vamos a analizar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a eliminar primero columnas de mas en test trabajar con datos mas pequeños\n",
    "df_properties_test.drop(['url', 'region_url','image_url','description'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_properties_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_properties.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_properties_test.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validamos los valores unicos y creamos un diccionario con los valores\n",
    "df_properties.type.unique()\n",
    "\n",
    "dic_type = {'house':1, 'apartment':2, 'duplex':3, 'townhouse':4, 'in-law':5, 'condo':6,\n",
    "       'cottage/cabin':7, 'manufactured':8, 'flat':9, 'loft':10, 'assisted living':11,\n",
    "       'land':12}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizamos la función map() para reemplazar los valores de la variable cualitativa con el diccionario\n",
    "df_properties[\"type_1\"] = df_properties[\"type\"].map(dic_type)\n",
    "\n",
    "#Hacemos lo mismo en el df de test\n",
    "df_properties_test[\"type_1\"] = df_properties_test[\"type\"].map(dic_type)\n",
    "\n",
    "df_properties_test.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laundry_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validamos los valores unicos y creamos un diccionario con los valores\n",
    "df_properties.laundry_options.unique()\n",
    "\n",
    "dic_laundry = {'w/d in unit':1, 'w/d hookups':2, 'laundry on site':3, 'laundry in bldg':4, 'no laundry on site':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizamos la función map() para reemplazar los valores de la variable cualitativa con el diccionario\n",
    "df_properties[\"laundry\"] = df_properties[\"laundry_options\"].map(dic_laundry)\n",
    "\n",
    "#Hacemos lo mismo en el df de test\n",
    "df_properties_test[\"laundry\"] = df_properties_test[\"laundry_options\"].map(dic_laundry)\n",
    "df_properties_test.head(5)\n",
    "#Observación: en df_properties_test la columna quedo como float debido a que tenemos los nulos o None en la columna. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos un 0 a los nulos\n",
    "df_properties_test['laundry'] = df_properties_test['laundry'].replace(np.nan, 0)\n",
    "df_properties_test.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parking_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validamos los valores unicos y creamos un diccionario con los valores\n",
    "df_properties.parking_options.unique()\n",
    "\n",
    "dic_parking = {'detached garage':1, 'off-street parking':2, 'attached garage':3,'carport':4, 'no parking':5, 'street parking':6, 'valet parking':7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizamos la función map() para reemplazar los valores de la variable cualitativa con el diccionario\n",
    "df_properties[\"parking\"] = df_properties[\"parking_options\"].map(dic_parking)\n",
    "\n",
    "#Hacemos lo mismo en el df de test\n",
    "df_properties_test[\"parking\"] = df_properties_test[\"parking_options\"].map(dic_parking)\n",
    "df_properties_test.head(5)\n",
    "#Observación: en df_properties_test la columna quedo como float debido a que tenemos los nulos o None en la columna. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignamos un 0 a los nulos\n",
    "df_properties_test['parking'] = df_properties_test['parking'].replace(np.nan, 0)\n",
    "df_properties_test.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar la frecuencia de cada valor en la columna\n",
    "value_counts = df_properties[\"state\"].value_counts()\n",
    "# Asignar un valor numérico a cada categoría de acuerdo a su frecuencia\n",
    "df_properties[\"state_freq\"] = df_properties[\"state\"].map(value_counts)\n",
    "\n",
    "\n",
    "#ahora en el test\n",
    "value_counts_test = df_properties_test[\"state\"].value_counts()\n",
    "df_properties_test[\"state_freq\"] = df_properties_test[\"state\"].map(value_counts_test)\n",
    "\n",
    "df_properties_test.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos las relaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df_properties.corr(method='spearman'), annot=True, fmt='.1g', cmap='coolwarm')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos columnas y creamos de nuevo el modelo árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a eliminar primero columnas de mas en test trabajar con datos mas pequeños\n",
    "#df_properties.drop(['laundry_options', 'parking_options','state'], axis=1, inplace=True)\n",
    "#df_properties_test.drop(['laundry_options', 'parking_options','state'], axis=1, inplace=True)\n",
    "\n",
    "#Definimos columnas a utilizar\n",
    "columnas = ['sqfeet','beds','baths','cats_allowed','dogs_allowed','wheelchair_access','type_1','laundry','state_freq','parking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos un objeto de la clase DecisionTreeClassifier\n",
    "\n",
    "clf1 = DecisionTreeClassifier(max_depth = 3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo\n",
    "X = df_properties[columnas]  # Denotamos X con mayúscula ya que incluye más de un atributo\n",
    "y = df_properties.category_price # Etiqueta a predecir\n",
    "clf1.fit(X.values,y.values) #entrenamos con train\n",
    "\n",
    "# Predecimos\n",
    "y_pred = clf1.predict(X.values)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(\"La precisión del modelo es: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos el modelo con el archivo de test\n",
    "X_train = df_properties[columnas]\n",
    "y_train = df_properties['category_price']\n",
    "\n",
    "X_test = df_properties_test[columnas]\n",
    "\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf1.predict(X_test)\n",
    "\n",
    "df_properties_test['pred']= y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_properties_test['pred'].to_csv('datasets/YamiGaliano.csv', index=False) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 1.3 reduciendo columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a eliminar primero columnas de mas en test trabajar con datos mas pequeños\n",
    "#df_properties.drop(['laundry_options', 'parking_options','state'], axis=1, inplace=True)\n",
    "#df_properties_test.drop(['laundry_options', 'parking_options','state'], axis=1, inplace=True)\n",
    "\n",
    "#Definimos columnas a utilizar\n",
    "columnas = ['sqfeet','beds','baths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos un objeto de la clase DecisionTreeClassifier\n",
    "\n",
    "clf2 = DecisionTreeClassifier(max_depth = 5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo\n",
    "X = df_properties[columnas]  # Denotamos X con mayúscula ya que incluye más de un atributo\n",
    "y = df_properties.category_price # Etiqueta a predecir\n",
    "clf2.fit(X.values,y.values) #entrenamos con train\n",
    "\n",
    "# Predecimos\n",
    "y_pred = clf2.predict(X.values)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(\"La precisión del modelo es: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos el modelo con el archivo de test\n",
    "X_train = df_properties[columnas]\n",
    "y_train = df_properties['category_price']\n",
    "\n",
    "X_test = df_properties_test[columnas]\n",
    "\n",
    "clf2 = DecisionTreeClassifier()\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf2.predict(X_test)\n",
    "\n",
    "df_properties_test['pred']= y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_properties_test['pred'].to_csv('datasets/YamiGaliano.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 1.4 vecinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = ['sqfeet','beds','baths','cats_allowed','dogs_allowed','wheelchair_access','type_1','laundry','state_freq','parking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Instanciamos un objeto de la clase KNeighborsClassifier\n",
    "\n",
    "clf4 = KNeighborsClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo\n",
    "X = df_properties[columnas]  # Denotamos X con mayúscula ya que incluye más de un atributo\n",
    "y = df_properties.category_price # Etiqueta a predecir\n",
    "\n",
    "clf4.fit(X.values,y.values)\n",
    "# Predecimos\n",
    "\n",
    "y_pred = clf4.predict(X.values)\n",
    "# Evaluamos\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(\"La precisión del modelo es: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos el modelo con el archivo de test\n",
    "X_train = df_properties[columnas]\n",
    "y_train = df_properties['category_price']\n",
    "\n",
    "X_test = df_properties_test[columnas]\n",
    "\n",
    "clf2 = DecisionTreeClassifier()\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf2.predict(X_test)\n",
    "\n",
    "df_properties_test['pred']= y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_properties_test['pred'].to_csv('datasets/YamiGaliano.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (v3.10.8:aaaf517424, Oct 11 2022, 10:14:40) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
